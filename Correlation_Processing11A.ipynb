{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b35ba35",
   "metadata": {},
   "source": [
    "<center><h1 style=\"color:#1a1a1a;\n",
    "                    font-size:3em\">\n",
    "        NHANES - MTech Project \n",
    "        </h1> \n",
    "        <h2 style=\"color:#1a1a1a;\n",
    "                    font-size:2em\">\n",
    "        Feature Selection - Previous Studies fields - Correlation - Data collection (Non Lab)\n",
    "       </h2>\n",
    "       <h3 style=\"color:#1a1a1a;\n",
    "                    font-size:2em\">\n",
    "        Prakash Easow Thomas - 2022DA04285 - June 2024\n",
    "       </h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29c4a6",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries and Reading the Datasets\n",
    "\n",
    "## 1.1 Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50efd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31170940",
   "metadata": {},
   "source": [
    "## 1.2 Reading the NHANES 2018 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2362a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1lab  = pd.read_csv('C:\\Prakash\\Personal\\Studies\\Techincal\\MTech. Data Science and Engineering\\Semester-wise\\Semester-I\\Study\\Sem-I - 0- Python Fundamentals for Data Science (S1-22_DSECLPFDS)\\PythonPgm\\MTech-Proj03-NHANES-2018\\Data\\laboratory.csv')\n",
    "df2demo = pd.read_csv('C:\\Prakash\\Personal\\Studies\\Techincal\\MTech. Data Science and Engineering\\Semester-wise\\Semester-I\\Study\\Sem-I - 0- Python Fundamentals for Data Science (S1-22_DSECLPFDS)\\PythonPgm\\MTech-Proj03-NHANES-2018\\Data\\demographics.csv')\n",
    "df3diet = pd.read_csv('C:\\Prakash\\Personal\\Studies\\Techincal\\MTech. Data Science and Engineering\\Semester-wise\\Semester-I\\Study\\Sem-I - 0- Python Fundamentals for Data Science (S1-22_DSECLPFDS)\\PythonPgm\\MTech-Proj03-NHANES-2018\\Data\\dietary.csv')\n",
    "df4exam = pd.read_csv('C:\\Prakash\\Personal\\Studies\\Techincal\\MTech. Data Science and Engineering\\Semester-wise\\Semester-I\\Study\\Sem-I - 0- Python Fundamentals for Data Science (S1-22_DSECLPFDS)\\PythonPgm\\MTech-Proj03-NHANES-2018\\Data\\examination.csv')\n",
    "df5ques = pd.read_csv('C:\\Prakash\\Personal\\Studies\\Techincal\\MTech. Data Science and Engineering\\Semester-wise\\Semester-I\\Study\\Sem-I - 0- Python Fundamentals for Data Science (S1-22_DSECLPFDS)\\PythonPgm\\MTech-Proj03-NHANES-2018\\Data\\questionnaire.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466a16aa",
   "metadata": {},
   "source": [
    "## 1.3 Variables from the Previous Studies (Excluding lab Variables) + HbA1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6973330-c63c-4a11-9981-21ed90ba0f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns_to_select = [\n",
    "'RIDAGEYR',         #\tAge in years at screening\n",
    "'RIDRETH3',         #\tRace/Hispanic origin w/ NH Asian\n",
    "'RIAGENDR',         #\tGender\n",
    "'PAQ706',           #  Days physically active at least 60 min.\n",
    "'PAQ605',           #  Vigorous work activity\n",
    "'PAQ620',           #\tModerate work activity\n",
    "'PAQ650',           #\tVigorous recreational activities\n",
    "'PAQ665',           #\tModerate recreational activities\n",
    "'BMXBMI',           #\tBody Mass Index (kg/m**2)\n",
    "'DIQ175A',          #\tFamily history\n",
    "'RHQ162',           #\tDuring pregnancy, told you have diabetes\n",
    "'DR1TALCO',         #\tAlcohol (gm)\n",
    "'DID260',           #\tHow often check blood for glucose/sugar\n",
    "'BPXOSY1',          #\tSystolic - 1st oscillometric reading\n",
    "'BPXODI1',          #\tDiastolic - 1st oscillometric reading\n",
    "'BPXOSY2',          #\tSystolic - 2nd oscillometric reading\n",
    "'BPXODI2',          #\tDiastolic - 2nd oscillometric reading\n",
    "'BPXOSY3',          #\tSystolic - 3rd oscillometric reading\n",
    "'BPXODI3',          #\tDiastolic - 3rd oscillometric reading\n",
    "'MCQ160B',          #\tEver told had congestive heart failure\n",
    "'DS2TCHOL',         #\tCholesterol (mg)\n",
    "'DSQTCHOL',         #\tCholesterol (mg)\n",
    "'DMDEDUC3',         #\tEducation level - Children/Youth 6-19\n",
    "'DMDEDUC2',         #\tEducation level - Adults 20+\n",
    "'CBD765',           #\tRespondent's education level\n",
    "'BPD035',           #\tAge told had hypertension\n",
    "'BPQ040A',          #\tTaking prescription for hypertension\n",
    "#'INQ020',           #\tIncome from wages/salaries\n",
    "#'INQ012',           #\tIncome from self employment\n",
    "#'INQ030',           #\tIncome from Social Security or RR\n",
    "#'INQ060',           #\tIncome from other disability pension\n",
    "#'INQ080',           #\tIncome from retirement/survivor pension\n",
    "#'INQ090',           #\tIncome from Supplemental Security Income\n",
    "#'INQ132',           #\tIncome from state/county cash assistance\n",
    "#'INQ140',           #\tIncome from interest/dividends or rental\n",
    "#'INQ150',           #\tIncome from other sources\n",
    "'IND235',           #\tMonthly family income\n",
    "'DIQ050',           #\tTaking insulin now\n",
    "'RIDEXPRG',         #\tPregnancy status at exam\n",
    "'SLD012',           #\tSleep hours - weekdays or workdays\n",
    "'BMXWAIST',         #\tWaist Circumference (cm)\n",
    "'DIQ070',            #  Take diabetic pills to lower blood sugar\n",
    "'LBXGH'             #   Glycohemoglobin (%) HbA1c\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a2a23-e824-4d38-a5be-63fa0f8ecb16",
   "metadata": {},
   "source": [
    "# 2. Merging and Selection of Data - NHANES 2018 Data\n",
    "\n",
    "## 2.1 Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db4b51ac-ce49-4990-a36d-e36069115f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files merged successfully into 'Before_Full_Feature_Selection_09_Data.csv'\n"
     ]
    }
   ],
   "source": [
    "common_key = 'SEQN'\n",
    "# Merge the DataFrames\n",
    "merged_dfNHAENES2018 = df1lab.merge(df2demo, on=common_key, how='outer')\n",
    "merged_dfNHAENES2018 = merged_dfNHAENES2018.merge(df3diet, on=common_key, how='outer')\n",
    "merged_dfNHAENES2018 = merged_dfNHAENES2018.merge(df4exam, on=common_key, how='outer')\n",
    "merged_dfNHAENES2018 = merged_dfNHAENES2018.merge(df5ques, on=common_key, how='outer')\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_dfNHAENES2018.to_csv('C:\\Prakash\\Personal\\Studies\\Techincal\\MTech. Data Science and Engineering\\Semester-wise\\Semester-I\\Study\\Sem-I - 0- Python Fundamentals for Data Science (S1-22_DSECLPFDS)\\PythonPgm\\MTech-Proj03-NHANES-2018\\Data\\Before_Full_Feature_Selection_09_Data.csv', index=False)\n",
    "\n",
    "print(\"Files merged successfully into 'Before_Full_Feature_Selection_09_Data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8146c6a-8428-4158-83aa-6d554481705c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>URXUMA</th>\n",
       "      <th>URXUMS</th>\n",
       "      <th>URXUCR</th>\n",
       "      <th>URXCRS</th>\n",
       "      <th>URDACT</th>\n",
       "      <th>WTSSGP2Y</th>\n",
       "      <th>SSAGP</th>\n",
       "      <th>WTSA2YR</th>\n",
       "      <th>URXUAS</th>\n",
       "      <th>...</th>\n",
       "      <th>WHD110</th>\n",
       "      <th>WHD120</th>\n",
       "      <th>WHD130</th>\n",
       "      <th>WHD140</th>\n",
       "      <th>WHQ150</th>\n",
       "      <th>WHQ190</th>\n",
       "      <th>WHQ200</th>\n",
       "      <th>WHQ030M</th>\n",
       "      <th>WHQ500</th>\n",
       "      <th>WHQ520</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93703.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93704.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93705.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2121.6</td>\n",
       "      <td>13.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93706.0</td>\n",
       "      <td>39.6</td>\n",
       "      <td>39.6</td>\n",
       "      <td>69.0</td>\n",
       "      <td>6099.6</td>\n",
       "      <td>57.39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93707.0</td>\n",
       "      <td>41.6</td>\n",
       "      <td>41.6</td>\n",
       "      <td>209.0</td>\n",
       "      <td>18475.6</td>\n",
       "      <td>19.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24984.393699</td>\n",
       "      <td>5.09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SEQN  URXUMA  URXUMS  URXUCR   URXCRS  URDACT  WTSSGP2Y  SSAGP  \\\n",
       "0  93703.0     NaN     NaN     NaN      NaN     NaN       0.0    NaN   \n",
       "1  93704.0     NaN     NaN     NaN      NaN     NaN       0.0    NaN   \n",
       "2  93705.0     3.2     3.2    24.0   2121.6   13.33       NaN    NaN   \n",
       "3  93706.0    39.6    39.6    69.0   6099.6   57.39       NaN    NaN   \n",
       "4  93707.0    41.6    41.6   209.0  18475.6   19.90       NaN    NaN   \n",
       "\n",
       "        WTSA2YR  URXUAS  ...  WHD110  WHD120  WHD130  WHD140  WHQ150  WHQ190  \\\n",
       "0           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1           NaN     NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2           NaN     NaN  ...   150.0   130.0    63.0   170.0    62.0     2.0   \n",
       "3           NaN     NaN  ...     NaN     NaN     NaN   150.0    17.0     2.0   \n",
       "4  24984.393699    5.09  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "   WHQ200  WHQ030M  WHQ500  WHQ520  \n",
       "0     NaN      NaN     NaN     NaN  \n",
       "1     NaN      NaN     NaN     NaN  \n",
       "2     NaN      NaN     NaN     NaN  \n",
       "3     NaN      NaN     NaN     NaN  \n",
       "4     NaN      3.0     3.0     2.0  \n",
       "\n",
       "[5 rows x 2236 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dfNHAENES2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4470be56-2eea-4d45-a7cb-8c4ff8b80835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9254, 2236)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dfNHAENES2018.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223deb5e-7c1c-41e4-9d12-b8736f24afc1",
   "metadata": {},
   "source": [
    "## 2.2 Selection of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "773b850c-4ea5-4f08-8149-d45c65c27a35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9254, 34)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_columns = pd.Index(columns_to_select).intersection(merged_dfNHAENES2018.columns)\n",
    "merged_dfNHAENES2018_selected = merged_dfNHAENES2018[columns_to_select]\n",
    "merged_dfNHAENES2018_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fbbc90d-1514-4fd9-9007-797432eab319",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of NaN values in each column:\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "nan_counts = merged_dfNHAENES2018_selected.isna().sum()\n",
    "print(\"\\nCount of NaN values in each column:\")\n",
    "#print(nan_counts)\n",
    "print(type(nan_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f519b07-d750-49f8-aeb4-894ccb371c27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDAGEYR       0\n",
      "RIDRETH3       0\n",
      "RIAGENDR       0\n",
      "DIQ050       357\n",
      "IND235       653\n",
      "BMXBMI      1249\n",
      "BMXWAIST    1653\n",
      "DR1TALCO    1770\n",
      "BPXODI1     3111\n",
      "BPXOSY1     3111\n",
      "BPXOSY2     3131\n",
      "BPXODI2     3131\n",
      "SLD012      3141\n",
      "BPXOSY3     3160\n",
      "BPXODI3     3160\n",
      "LBXGH       3209\n",
      "PAQ665      3398\n",
      "PAQ650      3398\n",
      "PAQ605      3398\n",
      "PAQ620      3398\n",
      "MCQ160B     3685\n",
      "DMDEDUC2    3685\n",
      "PAQ706      6503\n",
      "DMDEDUC3    6948\n",
      "BPD035      7117\n",
      "BPQ040A     7117\n",
      "RHQ162      7141\n",
      "DIQ070      7580\n",
      "CBD765      7598\n",
      "DIQ175A     8109\n",
      "RIDEXPRG    8144\n",
      "DID260      8361\n",
      "DSQTCHOL    8821\n",
      "DS2TCHOL    8970\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sorted_series = nan_counts.sort_values()\n",
    "print(sorted_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9781c50b-275a-4e03-8ae4-d343283e7197",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing - NHANES 2018 Data\n",
    "         - Remove the Non-Numeric Fields \n",
    "         - Remove the records where (LBXGH) No HbA1c is not present  \n",
    "         - Initilized NaN with zeros   \n",
    "\n",
    "## 3.1  Removing the Non-Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8e9ddbb-ee82-4864-87e8-4632d92a5601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    for column in df.columns:\n",
    "        # Check if the column contains byte-strings\n",
    "        if df[column].dtype == object:\n",
    "            # Decode byte-strings to regular strings\n",
    "            df[column] = df[column].apply(lambda x: x.decode('utf-8') if isinstance(x, bytes) else x)\n",
    "        # Convert non-numeric values to NaN for numeric columns\n",
    "        df[column] = pd.to_numeric(df[column], errors='ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1416fc0b-aec7-4f73-bfad-97b7eda0d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RIDAGEYR  RIDRETH3  RIAGENDR  PAQ706  PAQ605  PAQ620  PAQ650  PAQ665  \\\n",
      "0          2.0       6.0       2.0     7.0     NaN     NaN     NaN     NaN   \n",
      "1          2.0       3.0       1.0     7.0     NaN     NaN     NaN     NaN   \n",
      "2         66.0       4.0       2.0     NaN     2.0     2.0     2.0     1.0   \n",
      "3         18.0       6.0       1.0     NaN     2.0     2.0     2.0     1.0   \n",
      "4         13.0       7.0       1.0     0.0     NaN     NaN     NaN     NaN   \n",
      "...        ...       ...       ...     ...     ...     ...     ...     ...   \n",
      "9249       0.0       2.0       1.0     NaN     NaN     NaN     NaN     NaN   \n",
      "9250      11.0       3.0       2.0     7.0     NaN     NaN     NaN     NaN   \n",
      "9251      77.0       3.0       2.0     NaN     2.0     2.0     2.0     2.0   \n",
      "9252       0.0       3.0       2.0     NaN     NaN     NaN     NaN     NaN   \n",
      "9253      64.0       4.0       1.0     NaN     2.0     2.0     2.0     2.0   \n",
      "\n",
      "      BMXBMI  DIQ175A  ...  CBD765  BPD035  BPQ040A  IND235  DIQ050  RIDEXPRG  \\\n",
      "0       17.5      NaN  ...     NaN     NaN      NaN    12.0     2.0       NaN   \n",
      "1       15.7      NaN  ...     3.0     NaN      NaN    12.0     2.0       NaN   \n",
      "2       31.7      NaN  ...     NaN    50.0      1.0     2.0     2.0       NaN   \n",
      "3       21.5      NaN  ...     NaN     NaN      NaN     NaN     2.0       NaN   \n",
      "4       18.1      NaN  ...     3.0     NaN      NaN    11.0     2.0       NaN   \n",
      "...      ...      ...  ...     ...     ...      ...     ...     ...       ...   \n",
      "9249     NaN      NaN  ...     NaN     NaN      NaN     8.0     NaN       NaN   \n",
      "9250     NaN      NaN  ...     NaN     NaN      NaN    10.0     2.0       NaN   \n",
      "9251     NaN      NaN  ...     NaN     NaN      NaN     NaN     2.0       NaN   \n",
      "9252     NaN      NaN  ...     NaN     NaN      NaN     5.0     NaN       NaN   \n",
      "9253     NaN     10.0  ...     NaN    40.0      1.0     7.0     2.0       NaN   \n",
      "\n",
      "      SLD012  BMXWAIST  DIQ070  LBXGH  \n",
      "0        NaN      48.2     NaN    NaN  \n",
      "1        NaN      50.0     NaN    NaN  \n",
      "2        8.0     101.8     NaN    6.2  \n",
      "3       10.5      79.3     NaN    5.2  \n",
      "4        NaN      64.1     NaN    5.6  \n",
      "...      ...       ...     ...    ...  \n",
      "9249     NaN       NaN     NaN    NaN  \n",
      "9250     NaN       NaN     NaN    NaN  \n",
      "9251     9.0       NaN     2.0    NaN  \n",
      "9252     NaN       NaN     NaN    NaN  \n",
      "9253     7.0       NaN     2.0    NaN  \n",
      "\n",
      "[9254 rows x 34 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\praka\\AppData\\Local\\Temp\\ipykernel_53960\\3940003188.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[column] = pd.to_numeric(df[column], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "merged_dfNHAENES2018_Cleaned =clean_data(merged_dfNHAENES2018_selected)\n",
    "print(merged_dfNHAENES2018_Cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d91bcb5-4af0-44e2-829c-eac70f982466",
   "metadata": {},
   "source": [
    "## 3.2  Removing the records where HbA1c(LBXGH) is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e63c411-d14e-4d7f-b21f-b899c70bcda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RIDAGEYR  RIDRETH3  RIAGENDR  PAQ706  PAQ605  PAQ620  PAQ650  PAQ665  \\\n",
      "0         66.0       4.0       2.0     NaN     2.0     2.0     2.0     1.0   \n",
      "1         18.0       6.0       1.0     NaN     2.0     2.0     2.0     1.0   \n",
      "2         13.0       7.0       1.0     0.0     NaN     NaN     NaN     NaN   \n",
      "3         66.0       6.0       2.0     NaN     2.0     2.0     2.0     1.0   \n",
      "4         75.0       4.0       2.0     NaN     2.0     1.0     2.0     2.0   \n",
      "...        ...       ...       ...     ...     ...     ...     ...     ...   \n",
      "5946      70.0       6.0       2.0     NaN     2.0     2.0     2.0     1.0   \n",
      "5947      42.0       1.0       1.0     NaN     1.0     1.0     2.0     2.0   \n",
      "5948      41.0       4.0       2.0     NaN     2.0     2.0     2.0     1.0   \n",
      "5949      14.0       4.0       2.0     4.0     NaN     NaN     NaN     NaN   \n",
      "5950      38.0       3.0       1.0     NaN     2.0     2.0     2.0     2.0   \n",
      "\n",
      "      BMXBMI  DIQ175A  ...  CBD765  BPD035  BPQ040A  IND235  DIQ050  RIDEXPRG  \\\n",
      "0       31.7      NaN  ...     NaN    50.0      1.0     2.0     2.0       NaN   \n",
      "1       21.5      NaN  ...     NaN     NaN      NaN     NaN     2.0       NaN   \n",
      "2       18.1      NaN  ...     3.0     NaN      NaN    11.0     2.0       NaN   \n",
      "3       23.7      NaN  ...     NaN    50.0      1.0     5.0     2.0       NaN   \n",
      "4       38.9      NaN  ...     NaN    71.0      1.0     3.0     2.0       NaN   \n",
      "...      ...      ...  ...     ...     ...      ...     ...     ...       ...   \n",
      "5946    20.0      NaN  ...     NaN     NaN      NaN     4.0     2.0       NaN   \n",
      "5947    35.8      NaN  ...     NaN     NaN      NaN    77.0     2.0       NaN   \n",
      "5948    26.1      NaN  ...     NaN     NaN      NaN    12.0     2.0       2.0   \n",
      "5949    45.6      NaN  ...     2.0     NaN      NaN     9.0     2.0       NaN   \n",
      "5950    36.1      NaN  ...     NaN    37.0      2.0     7.0     2.0       NaN   \n",
      "\n",
      "      SLD012  BMXWAIST  DIQ070  LBXGH  \n",
      "0        8.0     101.8     NaN    6.2  \n",
      "1       10.5      79.3     NaN    5.2  \n",
      "2        NaN      64.1     NaN    5.6  \n",
      "3        8.0      88.2     2.0    6.2  \n",
      "4        7.0     113.0     2.0    6.3  \n",
      "...      ...       ...     ...    ...  \n",
      "5946     8.5      82.2     1.0    7.4  \n",
      "5947     6.0     114.8     2.0    5.9  \n",
      "5948     8.0      86.4     NaN    5.2  \n",
      "5949     NaN     113.5     NaN    5.5  \n",
      "5950     8.0     122.0     NaN    5.4  \n",
      "\n",
      "[5951 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_dfNHAENES2018_Cleaned_numeric = merged_dfNHAENES2018_Cleaned.select_dtypes(include=[int, float])\n",
    "column_to_check_HbA1c ='LBXGH'\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV =merged_dfNHAENES2018_Cleaned_numeric.dropna(subset=[column_to_check_HbA1c])\n",
    "column_to_check_BMI = 'BMXBMI'\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV =merged_dfNHAENES2018_Cleaned_numeric_HBV.dropna(subset=[column_to_check_BMI])\n",
    "\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV =merged_dfNHAENES2018_Cleaned_numeric_HBV.reset_index(drop=True)\n",
    "\n",
    "#dataset_for_ML = dataset_for_ML.reset_index(drop=True)\n",
    "print(merged_dfNHAENES2018_Cleaned_numeric_HBV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ff8e2ac-e99a-48b9-b997-42641d85c211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of NaN values in each column:\n",
      "RIDAGEYR       0\n",
      "RIDRETH3       0\n",
      "RIAGENDR       0\n",
      "PAQ706      5187\n",
      "PAQ605       776\n",
      "PAQ620       776\n",
      "PAQ650       776\n",
      "PAQ665       776\n",
      "BMXBMI         0\n",
      "DIQ175A     4904\n",
      "RHQ162      3930\n",
      "DR1TALCO     486\n",
      "DID260      5158\n",
      "BPXOSY1      674\n",
      "BPXODI1      674\n",
      "BPXOSY2      685\n",
      "BPXODI2      685\n",
      "BPXOSY3      701\n",
      "BPXODI3      701\n",
      "MCQ160B     1011\n",
      "DS2TCHOL    5678\n",
      "DSQTCHOL    5557\n",
      "DMDEDUC3    4940\n",
      "DMDEDUC2    1011\n",
      "CBD765      5564\n",
      "BPD035      4057\n",
      "BPQ040A     4057\n",
      "IND235       375\n",
      "DIQ050         0\n",
      "RIDEXPRG    4956\n",
      "SLD012       537\n",
      "BMXWAIST     213\n",
      "DIQ070      4440\n",
      "LBXGH          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = merged_dfNHAENES2018_Cleaned_numeric_HBV.isna().sum()\n",
    "print(\"\\nCount of NaN values in each column:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bfd09f9-c64a-4e52-a06f-4a0b26a131c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['PAQ706'].isna(), 'PAQ706'] = 0\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['PAQ605'].isna(), 'PAQ605'] = 2\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['PAQ620'].isna(), 'PAQ620'] = 2\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['PAQ650'].isna(), 'PAQ650'] = 2\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['PAQ665'].isna(), 'PAQ665'] = 2\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['MCQ160B'].isna(), 'MCQ160B'] = 2\n",
    "#merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['INQ020'].isna(), 'INQ020'] = 2\n",
    "#merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['INQ012'].isna(), 'INQ012'] = 2\n",
    "#merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['INQ030'].isna(), 'INQ030'] = 2\n",
    "#merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['INQ060'].isna(), 'INQ060'] = 2\n",
    "#merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['INQ080'].isna(), 'INQ080'] = 2\n",
    "#merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['INQ090'].isna(), 'INQ090'] = 2\n",
    "#merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['INQ132'].isna(), 'INQ132'] = 2\n",
    "#merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['INQ140'].isna(), 'INQ140'] = 2\n",
    "#merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['INQ150'].isna(), 'INQ150'] = 2\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['BPQ040A'].isna(), 'BPQ040A'] = 2\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['DIQ050'].isna(), 'DIQ050'] = 2\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['DIQ070'].isna(), 'DIQ070'] = 2\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['RIDEXPRG'].isna(), 'RIDEXPRG'] = 2\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['DIQ175A'].isna(), 'DIQ175A'] = 2  \n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['RHQ162'].isna(), 'RHQ162'] = 2\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['SLD012'].isna(), 'SLD012'] = 8\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['BMXWAIST'].isna(), 'BMXWAIST'] = 34\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['DS2TCHOL'].isna(), 'DS2TCHOL'] = 160\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['DSQTCHOL'].isna(), 'DSQTCHOL'] = 160\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['DSQTCHOL'].isna(), 'DSQTCHOL'] = 160\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['DID260'].isna(), 'DID260'] = 0\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.loc[merged_dfNHAENES2018_Cleaned_numeric_HBV['BPD035'].isna(), 'BPD035'] = 0\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['DR1TALCO'].fillna(merged_dfNHAENES2018_Cleaned_numeric_HBV['DR1TALCO'].min(), inplace=True)\n",
    "#merged_dfNHAENES2018_Cleaned_numeric_HBV['DR1TALCO'].fillna(merged_dfNHAENES2018_Cleaned_numeric_HBV['DR1TALCO'].avg(), inplace=True)\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['IND235'].fillna(merged_dfNHAENES2018_Cleaned_numeric_HBV['IND235'].min(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "190a6420-db80-4330-999e-7c7b86262a9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of NaN values in each column:\n",
      "RIDAGEYR       0\n",
      "RIDRETH3       0\n",
      "RIAGENDR       0\n",
      "PAQ706         0\n",
      "PAQ605         0\n",
      "PAQ620         0\n",
      "PAQ650         0\n",
      "PAQ665         0\n",
      "BMXBMI         0\n",
      "DIQ175A        0\n",
      "RHQ162         0\n",
      "DR1TALCO       0\n",
      "DID260         0\n",
      "BPXOSY1      674\n",
      "BPXODI1      674\n",
      "BPXOSY2      685\n",
      "BPXODI2      685\n",
      "BPXOSY3      701\n",
      "BPXODI3      701\n",
      "MCQ160B        0\n",
      "DS2TCHOL       0\n",
      "DSQTCHOL       0\n",
      "DMDEDUC3    4940\n",
      "DMDEDUC2    1011\n",
      "CBD765      5564\n",
      "BPD035         0\n",
      "BPQ040A        0\n",
      "IND235         0\n",
      "DIQ050         0\n",
      "RIDEXPRG       0\n",
      "SLD012         0\n",
      "BMXWAIST       0\n",
      "DIQ070         0\n",
      "LBXGH          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = merged_dfNHAENES2018_Cleaned_numeric_HBV.isna().sum()\n",
    "print(\"\\nCount of NaN values in each column:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86f98422-4932-418c-a4b7-1d343cf88e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_77_99_Monthly_family_income(row,field):\n",
    "    if row[field] == 77  or row[field] == 99:\n",
    "        row[field] = 0\n",
    "        return row[field] \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['IND235'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_77_99_Monthly_family_income, axis=1, field='IND235')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96fed773-139f-4b2b-8612-8080beb2bbc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_999_DID260(row,field):\n",
    "    if row[field] == 999:\n",
    "        row[field] = 0\n",
    "        return row[field] \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['DID260'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_999_DID260, axis=1, field='DID260')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40777f80-e43d-41fb-89a8-bec2e6a70675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_99_DIQ175A(row,field):\n",
    "    if row[field] == 99:\n",
    "        row[field] = 0\n",
    "        return row[field] \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['DIQ175A'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_99_DIQ175A, axis=1, field='DIQ175A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47b961ca-3b14-455e-8b36-e8db3749b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_9_RHQ162(row,field):\n",
    "    if row[field] == 9:\n",
    "        row[field] = 0\n",
    "        return row[field] \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['RHQ162'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_9_RHQ162, axis=1, field='RHQ162')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26371e26-e921-42fd-a728-06f0e1ab3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_999_DID260(row,field):\n",
    "    if row[field] == 999:\n",
    "        row[field] = 0\n",
    "        return row[field] \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['DID260'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_999_DID260, axis=1, field='DID260')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68b3cea1-b482-4920-bf62-30bb8ba724c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_9_MCQ160B(row,field):\n",
    "    if row[field] == 999:\n",
    "        row[field] = 0\n",
    "        return row[field] \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['MCQ160B'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_9_MCQ160B, axis=1, field='MCQ160B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6daade15-084e-4b48-8d38-3c32ff23dbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_9_DIQ070(row,field):\n",
    "    if row[field] == 9:\n",
    "        row[field] = 0\n",
    "        return row[field] \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['DIQ070'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_9_DIQ070, axis=1, field='DIQ070')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "152a847a-bc88-4e03-8269-eb937c8a0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_9_DIQ050(row,field):\n",
    "    if row[field] == 9:\n",
    "        row[field] = 0\n",
    "        return row[field] \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['DIQ050'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_9_DIQ050, axis=1, field='DIQ050')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "292c0449-06b4-4fde-b6b4-7c47149ccb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_999_BPD035(row,field):\n",
    "    if row[field] == 999:\n",
    "        row[field] = 0\n",
    "        return row[field] \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['BPD035'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_999_BPD035, axis=1, field='BPD035')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4168f1e2-e0ed-4966-8147-4d8d0360e0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_na_for_Diastolic_value(row,field):\n",
    "    if pd.isna(row[field]) and row['RIDAGEYR'] <= 30:\n",
    "        row[field] = 80\n",
    "        return row[field] \n",
    "    elif pd.isna(row[field]):\n",
    "        row[field] = 80\n",
    "        return row[field]  \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['BPXODI1'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_na_for_Diastolic_value, axis=1, field='BPXODI1')\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['BPXODI2'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_na_for_Diastolic_value, axis=1, field='BPXODI2')\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['BPXODI3'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_na_for_Diastolic_value, axis=1, field='BPXODI3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da38e24d-e9bd-4be7-81ce-87b2faa8e142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_na_for_Systolic_value(row,field):\n",
    "    if pd.isna(row[field]) and row['RIDAGEYR'] <= 30:\n",
    "        row[field] = 120\n",
    "        return row[field] \n",
    "    elif pd.isna(row[field]):\n",
    "        row[field] = 120\n",
    "        return row[field]  \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['BPXOSY1'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_na_for_Systolic_value, axis=1, field='BPXOSY1')\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['BPXOSY2'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_na_for_Systolic_value, axis=1, field='BPXOSY2')\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['BPXOSY3'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_na_for_Systolic_value, axis=1, field='BPXOSY3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6eba03cb-b1e3-4693-88d1-c38a4f0c3100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_na_for_DMDEDUC2_value(row,field): # Adult\n",
    "    if pd.isna(row[field]) and row['RIDAGEYR'] <= 19 and (row['DMDEDUC3'] <= 9 or row['DMDEDUC3'] == 55 or row['DMDEDUC3']== 66):\n",
    "        row[field] = 1\n",
    "        return row[field] \n",
    "    elif pd.isna(row[field]) and row['RIDAGEYR'] <= 19 and row['DMDEDUC3'] > 9 and row['DMDEDUC3'] < 13:\n",
    "        row[field] = 2\n",
    "        return row[field]  \n",
    "    elif pd.isna(row[field]) and row['RIDAGEYR'] <= 19 and row['DMDEDUC3'] >= 13 and row['DMDEDUC3'] <= 15:\n",
    "        row[field] = 3\n",
    "        return row[field]  \n",
    "    elif (row[field] == 7 or  row[field] == 9):\n",
    "        row[field] = 1\n",
    "        return row[field] \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['DMDEDUC2'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_na_for_DMDEDUC2_value, axis=1, field='DMDEDUC2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc6d65c0-b45b-48eb-99f2-5e1b28bcdd6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_na_for_DMDEDUC3_value(row,field): # kids\n",
    "    if pd.isna(row[field])   and row['RIDAGEYR'] > 19 and row['DMDEDUC2'] == 1:\n",
    "        row[field] = 8\n",
    "        return row[field] \n",
    "    elif pd.isna(row[field]) and row['RIDAGEYR'] > 19 and row['DMDEDUC2'] == 2:\n",
    "        row[field] = 13\n",
    "        return row[field]  \n",
    "    elif pd.isna(row[field]) and row['RIDAGEYR'] > 19 and row['DMDEDUC2'] == 3:\n",
    "        row[field] = 14\n",
    "        return row[field]  \n",
    "    elif pd.isna(row[field]) and row['RIDAGEYR'] > 19 and (row['DMDEDUC2'] == 4 or row['DMDEDUC2'] == 5):\n",
    "        row[field] = 15\n",
    "        return row[field]  \n",
    "#    elif pd.isna(row[field]):\n",
    "#         print(row['SEQN'])\n",
    "#        row[field] = 0\n",
    "#        return row[field]  \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['DMDEDUC3'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_na_for_DMDEDUC3_value, axis=1, field='DMDEDUC3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "681ab710-ad3c-4439-9062-382a32678524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fill_na_for_CBD765_value(row,field):\n",
    "    # print(row[field])\n",
    "    if pd.isna(row[field]) and (row['DMDEDUC3'] < 13 or row['DMDEDUC3'] == 55 or row['DMDEDUC3']== 66 or row['DMDEDUC2'] < 3):\n",
    "        row[field] = 1\n",
    "        return row[field] \n",
    "    elif pd.isna(row[field]) and (row['DMDEDUC3'] == 13 or row['DMDEDUC3'] == 14 or row['DMDEDUC2'] == 3):\n",
    "        row[field] = 2\n",
    "        return row[field]  \n",
    "    elif pd.isna(row[field]) and (row['DMDEDUC2'] == 4 or row['DMDEDUC2'] == 5):\n",
    "        row[field] = 3\n",
    "        return row[field]  \n",
    "    else:\n",
    "        return row[field]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['CBD765'] = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(fill_na_for_CBD765_value, axis=1, field='CBD765')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a76f2cda-7b9e-48db-b193-39086cba7b27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5951, 35)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Processing Physically Active cases\n",
    "def setting_Physical_Activity(row):    \n",
    "    if row['PAQ706'] >= 3 and row['PAQ706']  < 7 and  row['RIDAGEYR'] <= 17:\n",
    "        return 1                                      \n",
    "    elif row['PAQ706']  == 7 and  row['RIDAGEYR'] <= 17:\n",
    "        return 2 # if more then set to 2\n",
    "    elif (row['PAQ620']  == 1  or row['PAQ665'] == 1) and  row['RIDAGEYR'] > 17 :\n",
    "        return 1 \n",
    "    elif (row['PAQ605'] == 1 or row['PAQ650'] == 1) and  row['RIDAGEYR'] > 17:\n",
    "        return 2 # if more then set to 2\n",
    "    else:\n",
    "        return 0\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['Physically_Active_Classify']  = merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(lambda row: setting_Physical_Activity(row), axis=1)\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db9b8596-b483-4ab4-894d-1c3d4d33770c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Classifying HbA1c Level\n",
    "def classify(row):\n",
    "    if row['DIQ070'] == 1 or row['DIQ050'] == 1:\n",
    "        return 1                 # 2 diabetic \n",
    "    elif row['LBXGH']   < 5.7 :\n",
    "        return 0\n",
    "    elif row ['LBXGH'] >= 5.7 and row['LBXGH'] < 6.5 :\n",
    "        return 1\n",
    "    else:\n",
    "        return 1             # 2 Diabetic\n",
    "#print(dataset_for_ML['LBXGH'])\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV['LBXGH_Classify']=  merged_dfNHAENES2018_Cleaned_numeric_HBV.apply(lambda row: classify(row), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5078f44-d1e1-4b97-8043-b37747253b30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      RIDAGEYR  RIDRETH3  RIAGENDR  PAQ706  PAQ605  PAQ620  PAQ650  PAQ665  \\\n",
      "0         66.0       4.0       2.0     0.0     2.0     2.0     2.0     1.0   \n",
      "1         18.0       6.0       1.0     0.0     2.0     2.0     2.0     1.0   \n",
      "2         13.0       7.0       1.0     0.0     2.0     2.0     2.0     2.0   \n",
      "3         66.0       6.0       2.0     0.0     2.0     2.0     2.0     1.0   \n",
      "4         75.0       4.0       2.0     0.0     2.0     1.0     2.0     2.0   \n",
      "...        ...       ...       ...     ...     ...     ...     ...     ...   \n",
      "5946      70.0       6.0       2.0     0.0     2.0     2.0     2.0     1.0   \n",
      "5947      42.0       1.0       1.0     0.0     1.0     1.0     2.0     2.0   \n",
      "5948      41.0       4.0       2.0     0.0     2.0     2.0     2.0     1.0   \n",
      "5949      14.0       4.0       2.0     4.0     2.0     2.0     2.0     2.0   \n",
      "5950      38.0       3.0       1.0     0.0     2.0     2.0     2.0     2.0   \n",
      "\n",
      "      BMXBMI  DIQ175A  ...  BPQ040A  IND235  DIQ050  RIDEXPRG  SLD012  \\\n",
      "0       31.7      2.0  ...      1.0     2.0     2.0       2.0     8.0   \n",
      "1       21.5      2.0  ...      2.0     1.0     2.0       2.0    10.5   \n",
      "2       18.1      2.0  ...      2.0    11.0     2.0       2.0     8.0   \n",
      "3       23.7      2.0  ...      1.0     5.0     2.0       2.0     8.0   \n",
      "4       38.9      2.0  ...      1.0     3.0     2.0       2.0     7.0   \n",
      "...      ...      ...  ...      ...     ...     ...       ...     ...   \n",
      "5946    20.0      2.0  ...      2.0     4.0     2.0       2.0     8.5   \n",
      "5947    35.8      2.0  ...      2.0     0.0     2.0       2.0     6.0   \n",
      "5948    26.1      2.0  ...      2.0    12.0     2.0       2.0     8.0   \n",
      "5949    45.6      2.0  ...      2.0     9.0     2.0       2.0     8.0   \n",
      "5950    36.1      2.0  ...      2.0     7.0     2.0       2.0     8.0   \n",
      "\n",
      "      BMXWAIST  DIQ070  LBXGH  Physically_Active_Classify  LBXGH_Classify  \n",
      "0        101.8     2.0    6.2                           1               1  \n",
      "1         79.3     2.0    5.2                           1               0  \n",
      "2         64.1     2.0    5.6                           0               0  \n",
      "3         88.2     2.0    6.2                           1               1  \n",
      "4        113.0     2.0    6.3                           1               1  \n",
      "...        ...     ...    ...                         ...             ...  \n",
      "5946      82.2     1.0    7.4                           1               1  \n",
      "5947     114.8     2.0    5.9                           1               1  \n",
      "5948      86.4     2.0    5.2                           1               0  \n",
      "5949     113.5     2.0    5.5                           1               0  \n",
      "5950     122.0     2.0    5.4                           0               0  \n",
      "\n",
      "[5951 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_dfNHAENES2018_Cleaned_numeric_HBV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26869cd4-0268-47f9-bd4e-616251f13cca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count of NaN values in each column:\n",
      "RIDAGEYR                      0\n",
      "RIDRETH3                      0\n",
      "RIAGENDR                      0\n",
      "PAQ706                        0\n",
      "PAQ605                        0\n",
      "PAQ620                        0\n",
      "PAQ650                        0\n",
      "PAQ665                        0\n",
      "BMXBMI                        0\n",
      "DIQ175A                       0\n",
      "RHQ162                        0\n",
      "DR1TALCO                      0\n",
      "DID260                        0\n",
      "BPXOSY1                       0\n",
      "BPXODI1                       0\n",
      "BPXOSY2                       0\n",
      "BPXODI2                       0\n",
      "BPXOSY3                       0\n",
      "BPXODI3                       0\n",
      "MCQ160B                       0\n",
      "DS2TCHOL                      0\n",
      "DSQTCHOL                      0\n",
      "DMDEDUC3                      0\n",
      "DMDEDUC2                      0\n",
      "CBD765                        0\n",
      "BPD035                        0\n",
      "BPQ040A                       0\n",
      "IND235                        0\n",
      "DIQ050                        0\n",
      "RIDEXPRG                      0\n",
      "SLD012                        0\n",
      "BMXWAIST                      0\n",
      "DIQ070                        0\n",
      "LBXGH                         0\n",
      "Physically_Active_Classify    0\n",
      "LBXGH_Classify                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_counts = merged_dfNHAENES2018_Cleaned_numeric_HBV.isna().sum()\n",
    "print(\"\\nCount of NaN values in each column:\")\n",
    "print(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "424358b7-c1bc-4307-800b-f3dfb995697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "'PAQ706',\n",
    "'PAQ605',\n",
    "'PAQ620',\n",
    "'PAQ650',\n",
    "'PAQ665',\n",
    "'LBXGH'\n",
    "]\n",
    "merged_dfNHAENES2018_Cleaned_numeric_HBV=merged_dfNHAENES2018_Cleaned_numeric_HBV.drop(columns_to_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "877366bf-2aa1-449a-948b-89cffceb6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dfNHAENES2018_Cleaned_numeric_HBV.to_csv('C:\\Prakash\\Personal\\Studies\\Techincal\\MTech. Data Science and Engineering\\Semester-wise\\Semester-I\\Study\\Sem-I - 0- Python Fundamentals for Data Science (S1-22_DSECLPFDS)\\PythonPgm\\MTech-Proj03-NHANES-2018\\Data\\After_DataPreprocessing_NoLab.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f6ceb-d85e-4c83-b215-12f7724fb0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
